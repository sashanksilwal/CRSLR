{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6456f844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ngochoang/opt/anaconda3/lib/python3.8/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.1-CAPI-1.13.3) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import georasters as gr\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import copy\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.inference import VariableElimination\n",
    "import networkx as nx\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ec3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vlm = np.genfromtxt('new_vlm.csv', delimiter=',')\n",
    "habitat_path = r\"../Week 7/habitat_nearest.shp\"\n",
    "habitat = gpd.read_file(habitat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e4e4e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "habitat.drop(columns=[\"col\", \"index_righ\", \"OBJECTID\", \"Id\", \"HabitatTyp\", \"HabitatT_1\", \"HabitatSub\", \"HabitatS_1\",\n",
    "                             \"RuleID\", \"Shape_Leng\", \"Shape_Area\", \"Habitats\"], axis=1, inplace=True)\n",
    "habitat.rename(columns={\"Fill\": \"Habitats\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ea88433",
   "metadata": {},
   "outputs": [],
   "source": [
    "habitat_groups = pd.read_excel('habitat_groups.xlsx', header=None)\n",
    "habitat_groups.rename(columns={0: \"Habitats\", 1: \"Groups\"}, inplace=True)\n",
    "habitat_groups.set_index(\"Habitats\", inplace=True)\n",
    "group_dict = habitat_groups.to_dict()['Groups']\n",
    "habitat[\"Habitat groups\"] = habitat[\"Habitats\"].map(group_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "723db34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_vlm_df = pd.DataFrame(vlm.flatten(), columns=['VLM'])\n",
    "inter_vlm_df.dropna(inplace=True)\n",
    "habitat[\"VLM\"] = inter_vlm_df.reset_index().VLM/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0064b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "habitat_new = habitat.drop(columns=['x', 'y', 'Habitats'], axis=1)\n",
    "habitat_new.rename(columns={'value': 'Elevation', 'Habitat groups': 'Habitats'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "691c16e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ngochoang/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4441: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "slr_values = pd.read_excel('slr.xlsx', header=None)\n",
    "slr = slr_values[[3]]\n",
    "slr.rename(columns={3: 'SLR'}, inplace=True)\n",
    "slr_dict = slr.reset_index().set_index('SLR').to_dict()['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "08face4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_classes(df, col='Intervals'):\n",
    "    counts = pd.DataFrame(df[col].value_counts())\n",
    "    if col == 'Intervals':\n",
    "        counts.sort_index(inplace=True)\n",
    "    sns.barplot(x=counts.index, y=col, palette=\"mako\", data=counts)\n",
    "    labels = plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "64ea4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_E(df):\n",
    "    # Step 1: Create Data Frame:\n",
    "    elevation_classes = pd.DataFrame()\n",
    "    elevation_classes['Elevation_Values'] = df.Elevation\n",
    "\n",
    "    # Step 2: Get Max and Min Values for Elevation\n",
    "    min_elev = df.Elevation.min()\n",
    "    max_elev = df.Elevation.max()\n",
    "\n",
    "    # Step 3: Create Intervals:\n",
    "    # Intervals\n",
    "    interval_0 = pd.cut(x=df[\"Elevation\"], bins=[1, 5, 10, max_elev])\n",
    "    interval_1 = pd.cut(x=df[\"Elevation\"], bins=[min_elev, -10, -1, 0], right=False)\n",
    "    interval_2 = pd.cut(x=df[\"Elevation\"], bins=[0, 1], include_lowest=True)\n",
    "    # Encoding\n",
    "    encoding_0 = pd.cut(x=df[\"Elevation\"], bins=[1, 5, 10, max_elev], labels=[4, 5, 6])\n",
    "    encoding_1 = pd.cut(x=df[\"Elevation\"], bins=[min_elev, -10, -1, 0], right=False, labels=[0, 1, 2])\n",
    "    encoding_2 = pd.cut(x=df[\"Elevation\"], bins=[0, 1], include_lowest=True, labels=[3])\n",
    "\n",
    "    # Step 4: Add intervals to dataframe:\n",
    "    elevation_classes['Intervals_0'] = interval_0\n",
    "    elevation_classes['Intervals_1'] = interval_1\n",
    "    elevation_classes['Intervals_2'] = interval_2\n",
    "    elevation_classes['Intervals'] = ''\n",
    "\n",
    "    elevation_classes.loc[ ((elevation_classes.Intervals_0.isnull()) & (elevation_classes.Intervals_1.isnull())), 'Intervals'] = interval_2\n",
    "    elevation_classes.loc[ ((elevation_classes.Intervals_0.isnull()) & (elevation_classes.Intervals_2.isnull())), 'Intervals'] = interval_1\n",
    "    elevation_classes.loc[ ((elevation_classes.Intervals_1.isnull()) & (elevation_classes.Intervals_2.isnull())), 'Intervals'] = interval_0\n",
    "\n",
    "    # Step 5: Add class encoding\n",
    "    elevation_classes['Encoding_0'] = encoding_0\n",
    "    elevation_classes['Encoding_1'] = encoding_1\n",
    "    elevation_classes['Encoding_2'] = encoding_2\n",
    "    elevation_classes['Encoding'] = ''\n",
    "\n",
    "    elevation_classes.loc[ ((elevation_classes.Encoding_0.isnull()) & (elevation_classes.Encoding_1.isnull())), 'Encoding'] = encoding_2\n",
    "    elevation_classes.loc[ ((elevation_classes.Encoding_0.isnull()) & (elevation_classes.Encoding_2.isnull())), 'Encoding'] = encoding_1\n",
    "    elevation_classes.loc[ ((elevation_classes.Encoding_1.isnull()) & (elevation_classes.Encoding_2.isnull())), 'Encoding'] = encoding_0\n",
    "\n",
    "    elevation_classes.drop(['Intervals_2', 'Intervals_1', 'Intervals_0', 'Encoding_2', 'Encoding_1', 'Encoding_0'],\n",
    "                           axis='columns', inplace=True)\n",
    "    \n",
    "    # Uncomment to see which number encodes which interval\n",
    "    # for i in range(7):\n",
    "    #     print(f\"Bin #{i}, interval: {elevation_classes[elevation_classes.Encoding == i].Intervals.iloc[i]}\")\n",
    "        \n",
    "    # Uncomment to visualize classes\n",
    "    # visualize_classes(elevation_classes)\n",
    "    \n",
    "    return elevation_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1ef68d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_VLM(df):\n",
    "    vlm_classes = pd.DataFrame()\n",
    "    vlm_classes['VLM_Values'] = df.VLM\n",
    "\n",
    "    # Intervals\n",
    "    vlm_intervals = pd.qcut(df.VLM, q=3)\n",
    "\n",
    "    # Encoding\n",
    "    vlm_encoding = pd.qcut(df.VLM, q=3, labels=[0, 1, 2])\n",
    "\n",
    "    vlm_classes['Intervals'] = vlm_intervals\n",
    "    vlm_classes['Encoding'] = vlm_encoding\n",
    "    \n",
    "    # Uncomment to see which number encodes which interval\n",
    "    # for i in range(3):\n",
    "    #     print(f\"Bin #{i}, interval: {vlm_classes[vlm_classes.Encoding == i].Intervals.iloc[i]}\")\n",
    "    \n",
    "    # Uncomment to visualize classes\n",
    "    # visualize_classes(vlm_classes)\n",
    "    \n",
    "    return vlm_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "74f42d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_habitat(df):\n",
    "    h_groups = ['Subaqueous', 'Rocky', 'Marsh/Salt Flats', 'Sandy', 'Forest', 'Developed']\n",
    "    h_encoding = [0, 1, 2, 3, 4, 5]\n",
    "    h_df = pd.DataFrame(list(zip(h_groups, h_encoding)), columns=['Habitat', 'Encoding'])\n",
    "    h_df.set_index('Habitat', inplace=True)\n",
    "    h_dict = h_df.to_dict()['Encoding']\n",
    "    \n",
    "    habitat_classes = pd.DataFrame()\n",
    "    habitat_classes['Values'] = df['Habitats']\n",
    "    habitat_classes['Encoding'] = df['Habitats'].map(h_dict)\n",
    "    \n",
    "    # Uncomment to see which number encodes which habitat group\n",
    "    # for i in range(6):\n",
    "    #     print(f\"Bin #{i}, habitat: {habitat_classes[habitat_classes.Encoding == i].Values.iloc[i]}\")\n",
    "    \n",
    "    # Uncomment to visualize classes\n",
    "    # visualize_classes(habitat_classes, col='Values')\n",
    "    \n",
    "    return habitat_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fdb02245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_AE(df):\n",
    "    # Step 1: Create Data Frame:\n",
    "    ae_classes = pd.DataFrame()\n",
    "    ae_classes['Values'] = df.AE\n",
    "\n",
    "    # Step 2: Get Max and Min Values for Elevation\n",
    "    min_AE = df.AE.min()\n",
    "    max_AE = df.AE.max()\n",
    "\n",
    "    # Step 3: Create Intervals:\n",
    "    # Intervals\n",
    "    interval_0 = pd.cut(x=df.AE, bins=[1, 5, 10, max_AE])\n",
    "    interval_1 = pd.cut(x=df.AE, bins=[min_AE, -12, -1, 0], right=False)\n",
    "    interval_2 = pd.cut(x=df.AE, bins=[0, 1], include_lowest=True)\n",
    "    # Encoding\n",
    "    encoding_0 = pd.cut(x=df.AE, bins=[1, 5, 10, max_AE], labels=[4, 5, 6])\n",
    "    encoding_1 = pd.cut(x=df.AE, bins=[min_AE, -12, -1, 0], right=False, labels=[0, 1, 2])\n",
    "    encoding_2 = pd.cut(x=df.AE, bins=[0, 1], include_lowest=True, labels=[3])\n",
    "\n",
    "    # Step 4: Add intervals to dataframe:\n",
    "    ae_classes['Intervals_0'] = interval_0\n",
    "    ae_classes['Intervals_1'] = interval_1\n",
    "    ae_classes['Intervals_2'] = interval_2\n",
    "    ae_classes['Intervals'] = ''\n",
    "\n",
    "    ae_classes.loc[ ((ae_classes.Intervals_0.isnull()) & (ae_classes.Intervals_1.isnull())), 'Intervals'] = interval_2\n",
    "    ae_classes.loc[ ((ae_classes.Intervals_0.isnull()) & (ae_classes.Intervals_2.isnull())), 'Intervals'] = interval_1\n",
    "    ae_classes.loc[ ((ae_classes.Intervals_1.isnull()) & (ae_classes.Intervals_2.isnull())), 'Intervals'] = interval_0\n",
    "\n",
    "    # Step 5: Add class encoding\n",
    "    ae_classes['Encoding_0'] = encoding_0\n",
    "    ae_classes['Encoding_1'] = encoding_1\n",
    "    ae_classes['Encoding_2'] = encoding_2\n",
    "    ae_classes['Encoding'] = ''\n",
    "\n",
    "    ae_classes.loc[ ((ae_classes.Encoding_0.isnull()) & (ae_classes.Encoding_1.isnull())), 'Encoding'] = encoding_2\n",
    "    ae_classes.loc[ ((ae_classes.Encoding_0.isnull()) & (ae_classes.Encoding_2.isnull())), 'Encoding'] = encoding_1\n",
    "    ae_classes.loc[ ((ae_classes.Encoding_1.isnull()) & (ae_classes.Encoding_2.isnull())), 'Encoding'] = encoding_0\n",
    "\n",
    "    ae_classes.drop(['Intervals_2', 'Intervals_1', 'Intervals_0', 'Encoding_2', 'Encoding_1', 'Encoding_0'],\n",
    "                    axis='columns', inplace=True)\n",
    "    \n",
    "    # Uncomment to see which number encodes which interval\n",
    "    # for i in range(7):\n",
    "    #     print(f\"Bin #{i}, interval: {ae_classes[ae_classes.Encoding == i].Intervals.iloc[i]}\")\n",
    "        \n",
    "    # Uncomment to visualize classes\n",
    "    # visualize_classes(ae_classes)\n",
    "    \n",
    "    return ae_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "593d1882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_df(df, slr):\n",
    "    encoded = pd.DataFrame()\n",
    "    elevation_classes = encode_E(df)\n",
    "    habitat_classes = encode_habitat(df)\n",
    "    vlm_classes = encode_VLM(df)\n",
    "    ae_classes = encode_AE(df)\n",
    "    \n",
    "    encoded['SLR'] = ''\n",
    "    encoded['E'] = elevation_classes.Encoding\n",
    "    encoded['VLM'] = vlm_classes.Encoding\n",
    "    encoded['AE'] = ae_classes.Encoding\n",
    "    encoded['LC'] = habitat_classes.Encoding\n",
    "    encoded.SLR = slr\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ed88817a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and encoding 7 scenarios: 47.73s\n"
     ]
    }
   ],
   "source": [
    "scenarios = []\n",
    "scenarios_encoded = []\n",
    "t = time()\n",
    "for i in range(7):\n",
    "    scenario = habitat_new.drop(columns=['geometry'], axis=1)\n",
    "    scenario['SLR'] = slr.iloc[i].SLR\n",
    "    scenario['AE'] = scenario.Elevation - scenario.SLR + scenario.VLM\n",
    "    scenarios.append(scenario)\n",
    "    scenarios_encoded.append(get_encoded_df(scenario, i))\n",
    "print(\"Creating and encoding 7 scenarios: %.2fs\" % (time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "37d0a0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd_cr = pd.read_csv('cpd_cr_new.csv', header=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0b5f729e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <th colspan=\"6\" halign=\"left\">0.0</th>\n",
       "      <th colspan=\"4\" halign=\"left\">1.0</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">5.0</th>\n",
       "      <th colspan=\"6\" halign=\"left\">6.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LC</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>...</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "AE 0.0                         1.0                   ... 5.0                  \\\n",
       "LC 0.0 1.0   2.0  3.0 4.0 5.0  0.0   1.0   2.0  3.0  ... 2.0 3.0   4.0   5.0   \n",
       "0    0   1  0.95  0.8   1   1  0.1  0.95  0.75  0.6  ...   0   0  0.05  0.05   \n",
       "1    1   0  0.05  0.2   0   0  0.9  0.05  0.25  0.4  ...   1   1  0.95  0.95   \n",
       "\n",
       "AE 6.0                      \n",
       "LC 0.0 1.0 2.0 3.0 4.0 5.0  \n",
       "0    1   0   0   0   0   0  \n",
       "1    0   1   1   1   1   1  \n",
       "\n",
       "[2 rows x 42 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpd_cr.columns = pd.MultiIndex.from_arrays([cpd_cr.iloc[0], cpd_cr.iloc[1]])\n",
    "cpd_cr = cpd_cr.iloc[2:].reset_index(drop=True)\n",
    "cpd_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b506c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_up_CR(df):\n",
    "    '''\n",
    "    CR column: 1 if P(dynamic >= 0.5), 0 otherwise\n",
    "    '''\n",
    "    cr_0 = df.apply(lambda row: cpd_cr.xs(row.AE, level='AE', axis=1)[row.LC].iloc[0], axis=1)\n",
    "    cr_1 = 1 - cr_0\n",
    "    cr = df.apply(lambda row: 1 if cpd_cr.xs(row.AE, level='AE', axis=1)[row.LC].iloc[0] <= 0.5 else 0, axis=1)\n",
    "    lookup = pd.DataFrame(list(zip(cr_0, cr_1, cr)), columns=['CR_0', 'CR_1', 'CR'])\n",
    "    return lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02a3ea",
   "metadata": {},
   "source": [
    "## Trying first scenario\n",
    "Not doing all scenarios at once yet, since looking up the CR for one scenario takes about 6 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "01cb9cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up CR: 705.53s\n"
     ]
    }
   ],
   "source": [
    "s0 = scenarios_encoded[0]\n",
    "t = time()\n",
    "cr0 = look_up_CR(s0)\n",
    "print(\"Looking up CR: %.2fs\" % (time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7904bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s0['CR'] = cr0.CR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4b7108aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "s0_test = s0.drop(columns=['CR'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "34710369",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianModel([('SLR', 'AE'),\n",
    "                       ('VLM', 'AE'),\n",
    "                       ('E', 'AE'),\n",
    "                       ('E', 'LC'),\n",
    "                       ('LC', 'CR'),\n",
    "                       ('AE', 'CR')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "be8721b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(s0, estimator=BayesianEstimator, prior_type=\"BDeu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76f0c5c",
   "metadata": {},
   "source": [
    "### Evaluating: binary predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "65f7ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "838a61a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 151/151 [00:00<00:00, 468.52it/s]\n"
     ]
    }
   ],
   "source": [
    "binary_preds = model.predict(s0_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "597842fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(s0['CR'], binary_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3127dd3b",
   "metadata": {},
   "source": [
    "### Evaluating: probability predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "bd49849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6c2e78a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for 5000 points: 86.96s\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "n = 5000\n",
    "prob_preds = model.predict_probability(s0_test[:n])\n",
    "print(f\"Making predictions for {n} points: %.2fs\" % (time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "863f4e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2229590960263953"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(cr0['CR_1'][:n], prob_preds['CR_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ace0c231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22295909602639521"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(cr0['CR_0'][:n], prob_preds['CR_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2968d7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
